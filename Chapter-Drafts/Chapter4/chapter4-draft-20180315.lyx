#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass book
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
\paragraph_spacing double
\noindent
Multidimensional Free Energy Computation
\end_layout

\begin_layout Standard
\paragraph_spacing double
\noindent
NOTE: THIS IS ACTUALLY CHAPTER 4 OF THE THESIS!!
\end_layout

\begin_layout Section
\paragraph_spacing double
\noindent
Importance of Free Energy Computation
\end_layout

\begin_layout Standard
\paragraph_spacing double
\noindent
The free energy of a chemical system governs the macroscopic behavior along
 with its thermal fluctuation including both the energetic and entropic
 influences, and the free energy landscape may contain one or more local
 minima representing configurations at the metastable states, which are
 the locations where the system spends a significant amount of time.
 The change in the system from the reactant to the product states, therefore,
 is represented in the free energy landscape as a transition from one metastable
 state to another.
 During the course of the reaction, the system needs to pass through the
 free energy barrier, where the probability of barrier crossing with respect
 to a metastable state labeled as state 1 is defined as,
\end_layout

\begin_layout Standard
\paragraph_spacing double
\noindent
\begin_inset Formula 
\[
p(1\to*)\propto e^{-\beta\Delta A_{1\to*}}
\]

\end_inset


\end_layout

\begin_layout Standard
Equation XX can be further rearranged such that for any configuration 
\begin_inset Formula $\mathbf{x}\in\Omega$
\end_inset

, the relative free energy of the configuration 
\begin_inset Formula $\mathbf{x}$
\end_inset

is related to the equilibrium probability of finding the configuration 
\begin_inset Formula $\mathbf{x}$
\end_inset

in the phase space,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
A(\mathbf{x})=-\beta^{-1}\ln p(\mathbf{x})
\]

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing double
Hypothetically, if a simulation is performed for an infinitely large amount
 of time, one could easily compute 
\begin_inset Formula $p(\mathbf{x})$
\end_inset

 for any configurations and then the configurational free energy landscape
 can be mapped.
 Nevertheless, as governed by equation XX, the higher the value 
\begin_inset Formula $\Delta A_{1\to*}$
\end_inset

 is, the longer timescale it would take to go from state 1 across the barrier.
 With limited computational resources, standard molecular dynamics (MD)
 simulation can only go up to the millisecond timescale, while 
\shape italic
ab initio
\shape default
 molecular dynamics (AIMD) fares far worse in timescale, only in the picosecond
 timescale due to a much higher cost for expensive first principles calculations.
 Hence, rare barrier crossing events typically are not well-sampled due
 to the issue of far less timescale affordable by current computational
 capabilities, and an attempt to compute the free energy landscape from
 any unbiased MD simulations would result in a noisy representation in the
 barrier region, hindering our insights on the dynamics of the transition
 state.
 Figure XX shows the one-dimensional free energy of 
\backslash
ce{NaCl + 495H2O} computed from the probability of finding the system at
 the cation - anion separation (
\begin_inset Formula $r_{+-}$
\end_inset

) ranging from 2.5 to 7.0 
\backslash
r{A}.
 It is clear that the noise around 
\begin_inset Formula $r_{+-}=3.0$
\end_inset

 
\backslash
r{A} is a result of inadequate sampling, because figure XX was computed
 from an unbiased simulation for only 240 ns, and according to our results
 in XX, there were only YY crossing events registered, which is not enough
 for us to deduce the dynamics of the rare events with confidence.
\end_layout

\begin_layout Standard
[PLACEHOLDER FOR FIGURE]
\end_layout

\begin_layout Standard
\paragraph_spacing double
Being able to compute relatively noise-free free energy landscapes, thus,
 opens up new insights into several relevant chemical processes, as well
 as their underlying mechanisms, as these free energy landscapes offer us
 insights into the relationship between all the metastable states and the
 dynamics around the transition state of amy chemical reactions.
 Nevertheless, as a chemical system may contain up to thousands of atoms,
 determining the free energy as a function of thousands of phase space variables
 is highly complex and expensive.
 However, relative free energies can be computed by constraining the absolute
 free energies into the collective variable space.
 Consequently, the relative free energy 
\begin_inset Formula $A(\xi_{1},\xi_{2},\ldots,\xi_{D})$
\end_inset

 can be written as a function of 
\begin_inset Formula $D$
\end_inset

 collective variables, where 
\begin_inset Formula $D$
\end_inset

 is the dimensionality of the problem which relates to the number of collective
 variables hypothesized to involve in the process where the reaction coordinate
 is a hypothetical linear combination of these 
\begin_inset Formula $D$
\end_inset

 variables that correlates with the slowest motion of the system across
 the free energy barrier.
 When written in terms of the collective variables, the free energy at 
\begin_inset Formula $\left\{ \xi_{1}^{*},\xi_{2}^{*},\ldots,\xi_{D}^{*}\right\} $
\end_inset

 is related to the natural logarithm marginal probability density,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
A\left(\xi_{1}^{*},\xi_{2}^{*},\ldots,\xi_{D}^{*}\right)=-\beta\ln\int\prod_{i=1}^{D}\delta\left(\xi_{i}(\mathbf{x})-\xi_{i}^{*}\right)e^{-\beta V(\mathbf{x})}d\mathbf{x}
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\mathbf{x}$
\end_inset

is a configuration snapshot.
 Therefore, 
\begin_inset Formula $A\left(\xi_{1}^{*},\xi_{2}^{*},\ldots,\xi_{D}^{*}\right)$
\end_inset

 is computed by integrating over all the possible snapshots in the simulation.
 By taking the derivative of equation XX, the gradient of 
\begin_inset Formula $A\left(\xi_{1}^{*},\xi_{2}^{*},\ldots,\xi_{D}^{*}\right)$
\end_inset

 is found to be related to the statistical average of the gradient of the
 potential 
\begin_inset Formula $V(\mathbf{x})$
\end_inset

,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\nabla_{\mathbf{x}}A=\left\langle \nabla_{\mathbf{x}}V\right\rangle 
\]

\end_inset


\end_layout

\begin_layout Standard
\paragraph_spacing double
Equations XX and YY imply that there exists free energy estimator, that
 is, a monomer unit that can be used to deduce the bigger picture of the
 free energy landscape.
 For equation XX, the free energy estimator is a local probability density
 
\begin_inset Formula $p_{i}(\mathbf{x})$
\end_inset

, whereas for equation YY, the free energy estimator is a mean force 
\begin_inset Formula $f_{i}=-\left\langle \nabla_{\mathbf{x}}V(\mathbf{x}_{i})\right\rangle $
\end_inset

.
 In order to get the free energy estimators for each part of the phase space,
 extensive sampling of that part is required to ensure statistical viability
 of the free energy estimators.
 Hence, the earliest approaches to compute free energy estimators came from
 constraining the simulations into several windows, where the local probability
 density or the mean force for each window can be computed using techniques
 such as Umbrella Sampling (US) for biased local probability densities,
 Thermodynamic Integration (TI) for the mean forces to be integrated into
 the free energy either through fixing the atoms involving in the reaction
 coordinates using SHAKE algorithm, or using a stiff harmonic restraint
 to limit sampling around the center of the windowwindow, which is better
 known as Umbrella Integration (UI) technique.
 Another approach to sample the CV space is through the holonomic constraints,
 which is used to confine the system to the collective variable hypersurface
 such as Blue Moon Sampling.
 However, the major disadvantage of the aforementioned techniques is the
 computational cost.
 To minimize possible statistical uncertainties of the estimators, a long
 simulation in each window is necessary for adequate sampling of any part
 of the collective variable space we desire to explore, including the rare
 event regions.
 Therefore, these kinds of simulations are costly due to the need to minimize
 sampling errors.
 There are two main kinds of error associating with the process.
 First of which is the statistical error due to the number of samples, and
 second of which is the error due to step size (i.e.
 the width of the window).
 In order to minimize these errors, one needs to reduce the width of window
 to reduce the error from the large step sizes, as well as performing very
 long simulation in each of the window to reduce the error from inaqequate
 sampling.
 While this is doable in one dimension, the cost to obtain samples in a
 
\begin_inset Formula $D$
\end_inset

 dimensional problem usually scales as 
\begin_inset Formula $\mathcal{O}(N_{window}^{D})$
\end_inset

, where 
\begin_inset Formula $N_{window}$
\end_inset

 is the number of windows usually required to obtain an acceptable result
 in one dimension.
 Moreover, as the dimensionality of the problem increases, the sampling
 area becomes larger, which necessitates even longer simulation per sampling
 area, further increasing total computational cost.
 Therefore, with limited computational resources, windowed simulations for
 multidimensional problems are inherently expensive and takes very long
 time even for classical MD simulations.
\end_layout

\begin_layout Standard
\paragraph_spacing double
In the previous decade, numbers of methods were introduced to selectively
 apply biases along the collective variable spaces in order to force the
 exploration away from free energy minima.
 Adaptive Biasing Force (ABF) makes use of sampling local free energy gradients
 and use it as the biasing force that pushes the dynamics away from the
 minima.
 Temperature-Accelerated Molecular Dynamics (TAMD) manipulates the dynamics
 in the collective variable space to make it faster than the actual coordinate
 space, and let the faster dynamics of the collective variable space pull
 the actual dynamics away from the minima, and Metadynamics (MTD) periodically
 adds repulsive bias potential along the visited regions in the collective
 variable space, thereby enhancing the rare event sampling frequency.
 These three methods can also be used to directly approximate the free energy
 in the collective variable space at very long time limit.
 While using these methods to compute the free energy sounds attractive,
 the main drawback is that the free energy can only be recovered at very
 long time limit.
 [MTD DRAWBACKS HERE] Also, methods like MTD or TAMD requires parameters
 adjustment, where a bad set of parameters may never give a good answer
 to the problems.
 However, these methods show potential uses as tools to quickly explore
 the CV space, as shown in the work by Maragliano and Vanden-Eijnden, as
 well as Cuendet and Tuckerman.
\end_layout

\begin_layout Standard
\paragraph_spacing double
In order to efficiently compute free energy landscapes, the key challenges
 of the methods mentioned in the above paragraphs, such as the need to compute
 local probability densities or the mean forces in sampling cases or the
 need to let the dynamics asymtotically converge to the free energy at very
 long time presented by the adaptive methods, need to be addressed.
 Recently, machine learning has become a buzzword in a scientific and engineerin
g community due to active fundings by large enterprises with huge computational
 resources driven by the need to predict underlying patterns in large amount
 of available data.
 In chemistry, it has been used in various applications; for example, approximat
ing ab initio energies, deriving newer force field models, or structural
 characterization of biomolecules or advanced materials.
 In free energy computation, Gaussian Process Regression (GPR) and Artificial
 Neural Networks (ANN) have successfully been applied for various polypeptide
 computational models with up to 8 dimensions using dihedral angles as the
 collective variables.
 However, GPR has been around for a significantly longer time, and it has
 recently been used in a one-dimensional free energy computation from an
 expensive AIMD simulation as the first example beyond polypeptide computational
 models.
 Nevertheless, its recent application in free energy computations implies
 that there is no established simulation protocols to be based on, especially
 for multidimensional problems in chemically reactive systems.
\end_layout

\begin_layout Standard
\paragraph_spacing double
GPR addresses the key challenges mentioned earlier by entirely eliminating
 the need to obtain statistical averages for free energy estimators by assuming
 statistical noises associated with each estimator is part of the procedure,
 and the conditional expectation of the free energy based on the available
 information of the estimators and the explored CV can be computed from
 the instantaneous force free energy estimators without the need to perform
 simulations for very long time, provided that the CV space of interest
 is adequately explored.
 Recent work by Mones et al.
 shows that the fastest exploration of the CV space can be achieved by using
 well-tempered metadynamics (WT-MTD) simulation with relatively long Gaussian
 deposition rate to ensure the quasi-equilibrium condition and a high bias
 factor to quickly encourage the system to quickly overcome the free energy
 barriers, which has an effect of giving a noisy reconstruction of the free
 energy landscape.
 As a result, one can construct multidimensional free energy landscapes
 with much less efforts due to the elimination of the need to sample 
\begin_inset Formula $N_{window}^{D}$
\end_inset

 areas in the CV space and the entire simulation was transformed into a
 single biased simulation that seeks to explore the CV space as quickly
 as possible, while a reconstruction of multidimensional free energy surface
 was fitted according to the maximum likelihood of the non-averaged instantaneou
s forces in the CV space as free energy estimators to obtain the best fit
 to the simulation data.
 In the next section, the theoretical aspect of GPR will be discussed in
 detail, as well as our proposed protocol for effective free energy reconstructi
on with GPR while ensuring a good agreement with traditional free energy
 computation methods while keeping the computational cost minimal.
 With our protocol, there are huge future implications for any kinds of
 computationally expensive problems.
\end_layout

\begin_layout Section
Gaussian Process Regression (GPR)
\end_layout

\begin_layout Subsection
Training Data
\end_layout

\begin_layout Standard
Gaussian process regression (GPR) is a class of machine learning algorithms,
 where one aims to make a prediction of the relationship between one set
 of input values to another set of output values based on the provided 
\shape italic
training data
\shape default
 
\begin_inset Formula $\mathcal{D}$
\end_inset

, which is a set of data obtained from observations or experimental evidence.
 A training data set 
\begin_inset Formula $\mathcal{D}$
\end_inset

 with 
\begin_inset Formula $N$
\end_inset

 training examples is written as 
\begin_inset Formula $\mathcal{D}=\left\{ (x_{i},y_{i})\right\} _{i=1}^{N}$
\end_inset

, where 
\begin_inset Formula $\mathbf{x}_{i}$
\end_inset

 is a 
\begin_inset Formula $1\times D$
\end_inset

 row vector called a feature vector with 
\begin_inset Formula $D$
\end_inset

 features.
 The main objective of any machine learning algorithm is to recover the
 underlying relationship 
\begin_inset Formula $f$
\end_inset

 that maps 
\begin_inset Formula $\mathbf{X}=\left[\mathbf{x}_{1}\,\mathbf{x}_{2}\,\ldots\,\mathbf{x}_{N}\right]^{T}$
\end_inset

 to 
\begin_inset Formula $\mathbf{y}=\left[y_{1}\,y_{2}\,\ldots\,y_{N}\right]^{T}$
\end_inset

.
 The predicted form of 
\begin_inset Formula $f$
\end_inset

 would then be used to make a prediction in a test set with 
\begin_inset Formula $N_{T}$
\end_inset

 entries 
\begin_inset Formula $\mathcal{T}=\left\{ (\mathbf{x}_{i}^{*},y_{i}^{*})\right\} _{i=1}^{N_{T}}$
\end_inset

 with an assertion that for any
\end_layout

\begin_layout Subsection
Gaussian Process and Covariance Kernel
\end_layout

\begin_layout Standard
blah blah blah
\end_layout

\begin_layout Subsection
Inference of the Conditional Expectation
\end_layout

\begin_layout Standard
blah blah blah
\end_layout

\begin_layout Section
Using GPR to Compute Free Energy Landscapes
\end_layout

\begin_layout Subsection
Fast Exploration of the Collective Variable Space
\end_layout

\begin_layout Standard
blah blah blah
\end_layout

\begin_layout Subsection
GPR Reconstruction of Free Energy Landscapes from Noisy Training Data
\end_layout

\begin_layout Standard
blah blah blah
\end_layout

\begin_layout Subsection
Error Analysis of GPR-constructed Free Energy Landscapes
\end_layout

\begin_layout Standard
blah blah blah
\end_layout

\end_body
\end_document
